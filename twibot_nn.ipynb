{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb384f74-e336-4d7f-bd39-297f476d7481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algeb\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15936f13-7269-42f8-9cb5-d3fd9243b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataframe of labeled tweets\n",
    "\n",
    "tweet_df = pd.read_json('Twibot-20/tweet.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbc27440-e6b3-42d8-aeb1-d227c84bcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_tweets(df):\n",
    "    \"\"\"\n",
    "    \"Melts\" a Twibot dataframe with lists in the tweet field into indexed rows for each tweet\n",
    "    Skips rows that have no tweets.\n",
    "    \"\"\"\n",
    "    out_df = pd.DataFrame()\n",
    "    for row in df.index:\n",
    "        if df.loc[row, 'tweet']:\n",
    "            df_dict = {}\n",
    "            df_dict['tweet'] = df.loc[row, 'tweet']\n",
    "            df_dict['tweet_index'] = range(len(df.loc[row, 'tweet']))\n",
    "            df_dict['ID'] = [ df.loc[row, 'ID'] for _ in range(len(df.loc[row, 'tweet'])) ]\n",
    "            df_dict['label'] = [ df.loc[row, 'label'] for _ in range(len(df.loc[row, 'tweet'])) ]\n",
    "            row_df = pd.DataFrame(df_dict)\n",
    "            out_df = pd.concat([out_df,row_df])\n",
    "        \n",
    "            \n",
    "    return out_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "922496a3-c24b-4ff7-a301-b7de0ac5f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tweets(df, sample_size=10, random_state=None):\n",
    "    \"\"\"\n",
    "    Creates a random sample of the Twibot dataframe with one tweet per line\n",
    "    \"\"\"\n",
    "    \n",
    "    out_df = df.sample(sample_size, replace=True, random_state=random_state).dropna()\n",
    "    \n",
    "    while len(out_df.index) < sample_size:\n",
    "        extra_df = df.sample(sample_size - len(out_df.index), replace=True, random_state=random_state).dropna()\n",
    "        out_df = pd.concat([out_df, extra_df])\n",
    "        \n",
    "    \n",
    "    out_df['tweet'] = out_df['tweet'].apply(lambda x: rnd.choice(x))\n",
    "    \n",
    "    return out_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88889701-12d0-4a67-9b1e-6b3a1dc43398",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "\n",
    "sample = sample_tweets(tweet_df, sample_size = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e0a2fae-63fd-462e-8421-02a3026f4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english', min_df=10, ngram_range=(1,4))\n",
    "\n",
    "X = vectorizer.fit_transform(sample.tweet)\n",
    "\n",
    "feat_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91d3216a-7bd9-45e8-be69-ab48ee89bea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14873"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b7d74c14-5346-4eaf-9e85-658d5f44ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ff54d211-84c5-46d0-8074-686136c25508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(sample.label)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd6be5cc-653f-4923-8ec6-65ac3f20a531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.6443 - accuracy: 0.6247\n",
      "Epoch 2/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.6018 - accuracy: 0.6838\n",
      "Epoch 3/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5865 - accuracy: 0.7045\n",
      "Epoch 4/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5758 - accuracy: 0.7204\n",
      "Epoch 5/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5675 - accuracy: 0.7311\n",
      "Epoch 6/20\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.5601 - accuracy: 0.7411\n",
      "Epoch 7/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5542 - accuracy: 0.7475\n",
      "Epoch 8/20\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.5489 - accuracy: 0.7534\n",
      "Epoch 9/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5443 - accuracy: 0.7590\n",
      "Epoch 10/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5397 - accuracy: 0.7648\n",
      "Epoch 11/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5366 - accuracy: 0.7677\n",
      "Epoch 12/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5334 - accuracy: 0.7714\n",
      "Epoch 13/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5304 - accuracy: 0.7746\n",
      "Epoch 14/20\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.5280 - accuracy: 0.7785\n",
      "Epoch 15/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5262 - accuracy: 0.7789\n",
      "Epoch 16/20\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.5237 - accuracy: 0.7816\n",
      "Epoch 17/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5213 - accuracy: 0.7850\n",
      "Epoch 18/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5198 - accuracy: 0.7867\n",
      "Epoch 19/20\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.5181 - accuracy: 0.7880\n",
      "Epoch 20/20\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.5167 - accuracy: 0.7893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1831f78de50>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb780005-14b3-48c6-a3a8-7f17bbf268bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sample_tweets(tweet_df, sample_size = 1000)\n",
    "X = vectorizer.transform(test_df.tweet).toarray()\n",
    "y = test_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "65b7ea62-f3bf-46ec-89cc-caa4bf209f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.6560 - accuracy: 0.6460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6559779047966003, 0.6460000276565552]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2cfc4e08-39fb-41d3-9d09-4550eb8697a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (32, 20)                  297480    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (32, 2)                   42        \n",
      "=================================================================\n",
      "Total params: 297,522\n",
      "Trainable params: 297,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
