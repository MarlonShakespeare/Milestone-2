{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from utils import stem_token, split_all_data\n",
    "\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Splitting the data...\n"
     ]
    }
   ],
   "source": [
    "data_dict = split_all_data(.8)\n",
    "train_df = data_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 Âµs Â± 12.7 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "stem_token(train_df['tweet'].iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 982944228304187392 - label: 1\n",
      " [('rt', 1), ('buffer', 1), ('but', 1), ('summersalt', 1), ('fast', 1), ('trajectori', 1), ('fuel', 1), ('earli', 1), ('fund', 1), ('style', 1)] \n",
      "\n",
      "user: 2408243229 - label: 1\n",
      " [('http', 1), ('co', 1), ('svg1mv9jj7', 1)] \n",
      "\n",
      "user: 861643695430524928 - label: 1\n",
      " [('rt', 1), ('graphixsli', 1), ('my', 1), ('entri', 1), ('artwork', 1), ('challeng', 1), ('thegenesisep', 1), ('realkaash', 1), ('http', 1), ('co', 1)] \n",
      "\n",
      "user: 197974105 - label: 0\n",
      " [('restaur', 2), ('wesweav', 1), ('order', 1), ('hardena', 1), ('waroeng', 1), ('surabaya', 1), ('intrigu', 1), ('long', 1), ('time', 1), ('ago', 1)] \n",
      "\n",
      "user: 1266022889725341696 - label: 1\n",
      " [('rt', 1), ('patehogan', 1), ('super', 1), ('bless', 1), ('receiv', 1), ('offer', 1), ('lagrang', 1), ('colleg', 1), ('coachbcrump', 1), ('coach_ruth01', 1)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing the tokenizer/lemmatizer\n",
    "for item in train_df.sample(5).itertuples():\n",
    "    tokenized = stem_token(item[3][0])\n",
    "    count = Counter(tokenized)\n",
    "    print(f'user: {item[1]} - label: {item[-1]}\\n', count.most_common(10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic_feature(row, components, thresh, random_state=None):\n",
    "    if row is not None:\n",
    "        vectorize = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', min_df=1)\n",
    "        nmf_model = NMF(n_components=components, init='nndsvd', max_iter=100000, random_state=random_state)\n",
    "        nmf_pipe = make_pipeline(vectorize, nmf_model)\n",
    "        \n",
    "        tweets = np.array(row)\n",
    "        W = nmf_pipe.fit_transform(tweets)\n",
    "        print(W)\n",
    "        \n",
    "        index_max = []\n",
    "        for index in range(W.shape[0]):\n",
    "            max_val_index = np.argmax(W[index]) if np.max(W[index]) > thresh else -1\n",
    "            index_max.append(max_val_index)\n",
    "        print(index_max)    \n",
    "        return len(set([index for index in index_max if index != -1]))/tweets.shape[0]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60622293 0.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         0.7210456  0.        ]\n",
      " [0.         0.7210456  0.        ]\n",
      " [0.42884922 0.         0.        ]\n",
      " [0.74257518 0.         0.        ]]\n",
      "[-1, 2, 1, 1, -1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML_w_tf_env\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 100000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_documents_train = ['The cat, dog, and duck were friends. \\\n",
    "                          The cat and duck met at the dog\\'s house despite the dog\\'s objections.', \n",
    "                   'Computers have power supplies that regulate power consumption.', \n",
    "                   'Plug in the monitor and turn on the computer. \\\n",
    "                     the monitor is now ready for use.', \n",
    "                   'You will find the plug on the right side of the screen.', \n",
    "                   'My friend likes coffee and cats.', \n",
    "                   'His dog gets along well with my friend.']\n",
    "extract_topic_feature(simple_documents_train, 3, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(ngram_range=(1, 2), stop_words=None, tokenizer=stem_token, min_df=1)\n",
    "nmf_model = NMF(n_components=20, init='nndsvd', max_iter=1000, random_state=None)\n",
    "nmf_pipe = make_pipeline(vectorize, nmf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = np.array(train_df['tweet'].loc[0])\n",
    "W = nmf_pipe.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_df['tweet'].loc[0]))\n",
    "print(tweets.shape)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @CarnivalCruise: ðŸŽ‰ Are you ready to see what our newest shipâ€™s name will be? ðŸŽ‰ Thanks to all our partners for helping us unbox the name.â€¦\n",
      "\n",
      "[0.         0.01299792 0.         0.08002773 0.         0.\n",
      " 0.0151254  0.02365543 0.         0.         0.         0.00308785\n",
      " 0.         0.0846081  0.         0.01539741 0.         0.\n",
      " 0.02472308 0.        ]\n",
      "Who has time for receipts? Not me. @epson receipt scanners make it easy. No mess = no stress! Check it out at https://t.co/ofqbTdz0Qk. https://t.co/BtYwuyz9N5\n",
      "\n",
      "[2.62949862e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 7.19983142e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.10196391e-05 2.81157716e-03 0.00000000e+00\n",
      " 5.80334800e-02 5.23719170e-04 0.00000000e+00 0.00000000e+00\n",
      " 4.26264627e-02 1.82492982e-03 1.89216302e-01 0.00000000e+00]\n",
      "Steady wants to encourage you to invest in your financial future. Connect your bank account to @TheSteadyApp and have access to benefits like income insights, online medical visits, and cash grants of up to $1,000! Get started today by visiting https://t.co/5w3AvWd8Q0. #Sponsored https://t.co/ZHBfP5xDMg\n",
      "\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56596758\n",
      " 0.         0.        ]\n",
      "Good one, @rishid. But letâ€™s see if y'all can do better than that. Come on, everybody. Show me your best #HandShaq! #ad https://t.co/xCloeLRfuM https://t.co/urVSOfTmT2\n",
      "\n",
      "[0.00105148 0.         0.00054637 0.00188765 0.         0.\n",
      " 0.         0.         0.         0.23155249 0.         0.\n",
      " 0.04520281 0.00307931 0.         0.07944518 0.         0.\n",
      " 0.         0.        ]\n",
      "#lsunationalchamps\n",
      "\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.41765229e-26 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "for tw in range(5):\n",
    "    print(tweets[tw])\n",
    "    print(W[tw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe336406e9fe7934cb9574bced87d36d9641f95c336376560cd58afbe64d3c8c"
  },
  "kernelspec": {
   "display_name": "ML_w_tf_env",
   "language": "python",
   "name": "ml_w_tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
